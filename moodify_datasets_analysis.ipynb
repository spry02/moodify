{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ae17adb",
   "metadata": {},
   "source": [
    "# Analiza zbiorów danych z emocjami\n",
    "\n",
    "Ten notatnik pobiera i analizuje dwa zbiory danych:\n",
    "- **AffectNet** - zbiór obrazów z emocjami\n",
    "- **Emotion** - zbiór tekstowy z emocjami\n",
    "\n",
    "Celem jest porównanie i analiza emocji w obu zbiorach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fbbd5e",
   "metadata": {},
   "source": [
    "## 1. Instalacja bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9ff81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kagglehub datasets matplotlib pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbdef1d",
   "metadata": {},
   "source": [
    "## 2. Pobranie zbioru AffectNet\n",
    "\n",
    "Pobieramy **AffectNet** z Kaggle używając `kagglehub`. Zbiór zawiera ~450,000 zdjęć twarzy z 8 kategoriami emocji zebranych z internetu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b50a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"mstjebashazida/affectnet\")\n",
    "\n",
    "print(\"Ścieżka do plików zbioru AffectNet:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74811201",
   "metadata": {},
   "source": [
    "## 3. Pobranie zbioru Emotion (dla modelu Transformer)\n",
    "\n",
    "Pobieramy **Emotion Dataset** z Hugging Face - zawiera 20,000 tweetów w języku angielskim z 6 kategoriami emocji. Idealny do trenowania modeli Transformer (BERT, DistilBERT, RoBERTa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2c56c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "emotions = load_dataset(\"dair-ai/emotion\")\n",
    "\n",
    "print(\"Zbiór Emotion został pobrany pomyślnie!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ae1e73",
   "metadata": {},
   "source": [
    "## 4. Wczytanie i eksploracja AffectNet\n",
    "\n",
    "Sprawdzamy pełną strukturę katalogów, listę podfolderów i liczbę plików. \n",
    "**Cel:** Zrozumieć organizację danych (Train/Test/emotion_folders) przed dalszą analizą."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2503b849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Zawartość katalogu AffectNet:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for root, dirs, files in os.walk(path):\n",
    "    level = root.replace(path, '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f'{indent}{os.path.basename(root)}/')\n",
    "    \n",
    "    if dirs:\n",
    "        subindent = ' ' * 2 * (level + 1)\n",
    "        print(f'{subindent}Foldery: {dirs}')\n",
    "    \n",
    "    if files:\n",
    "        subindent = ' ' * 2 * (level + 1)\n",
    "        print(f'{subindent}Liczba plików: {len(files)}')\n",
    "        for file in files[:3]:\n",
    "            print(f'{subindent}  {file}')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Ścieżka bazowa: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35cf9bf",
   "metadata": {},
   "source": [
    "## 5. Wyświetlenie przykładowych zdjęć z AffectNet\n",
    "\n",
    "Wizualizacja 6 losowych zdjęć do sprawdzenia jakości i różnorodności danych.\n",
    "**Metoda:** Rekursywne wyszukiwanie wszystkich plików graficznych (jpg, jpeg, png) w całym katalogu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f259265",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "image_files = []\n",
    "for ext in ['*.jpg', '*.jpeg', '*.png']:\n",
    "    image_files.extend(glob.glob(os.path.join(path, '**', ext), recursive=True))\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(min(6, len(image_files))):\n",
    "    img = Image.open(image_files[i])\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(f'Obraz {i+1}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nZnaleziono {len(image_files)} obrazów w zbiorze AffectNet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb30dc37",
   "metadata": {},
   "source": [
    "## 6. Analiza rozkładu emocji w AffectNet\n",
    "\n",
    "Zliczamy obrazy według kategorii emocji na podstawie struktury folderów.\n",
    "**Jak to działa:** Każda emocja ma osobny folder (np. `happy/`, `sad/`), więc analizujemy ścieżki plików i rozpoznajemy emocję z nazwy folderu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb8e353",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "affectnet_emotions = {\n",
    "    'neutral': 'Neutralny',\n",
    "    'happy': 'Szczęście',\n",
    "    'sad': 'Smutek',\n",
    "    'surprise': 'Zaskoczenie',\n",
    "    'fear': 'Strach',\n",
    "    'disgust': 'Wstręt',\n",
    "    'anger': 'Złość',\n",
    "    'contempt': 'Pogarda'\n",
    "}\n",
    "\n",
    "emotion_counts = Counter()\n",
    "for img_path in image_files:\n",
    "    for part in Path(img_path).parts:\n",
    "        if part.lower() in affectnet_emotions:\n",
    "            emotion_counts[affectnet_emotions[part.lower()]] += 1\n",
    "            break\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8', '#F7DC6F', '#BB8FCE', '#85C1E2']\n",
    "plt.bar(emotion_counts.keys(), emotion_counts.values(), color=colors, edgecolor='black', linewidth=1.5)\n",
    "plt.xlabel('Emocja', fontsize=13, fontweight='bold')\n",
    "plt.ylabel('Liczba obrazów', fontsize=13, fontweight='bold')\n",
    "plt.title('Rozkład emocji w zbiorze AffectNet', fontsize=15, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"STATYSTYKI AFFECTNET\")\n",
    "print(\"=\"*60)\n",
    "total = sum(emotion_counts.values())\n",
    "for emotion, count in sorted(emotion_counts.items()):\n",
    "    percentage = (count / total) * 100\n",
    "    print(f\"{emotion:<15} {count:>6} ({percentage:>5.1f}%)\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'ŁĄCZNIE':<15} {total:>6} (100.0%)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760745ab",
   "metadata": {},
   "source": [
    "## 7. Wczytanie i eksploracja zbioru Emotion\n",
    "\n",
    "Wyświetlamy podstawowe informacje: strukturę zbioru, podział na train/validation/test oraz przykładowe teksty z etykietami.\n",
    "**Etykiety:** Emocje są reprezentowane jako liczby 0-5, które zaraz zmapujemy na czytelne nazwy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9f3d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Struktura zbioru Emotion:\")\n",
    "print(emotions)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"Podział zbioru:\")\n",
    "for split in emotions.keys():\n",
    "    print(f\"  {split}: {len(emotions[split])} przykładów\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"Przykładowe dane ze zbioru treningowego:\")\n",
    "for i in range(3):\n",
    "    print(f\"\\nPrzykład {i+1}:\")\n",
    "    print(f\"  Tekst: {emotions['train'][i]['text']}\")\n",
    "    print(f\"  Emocja: {emotions['train'][i]['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a7287c",
   "metadata": {},
   "source": [
    "## 8. Analiza rozkładu emocji w zbiorze tekstowym\n",
    "\n",
    "Mapujemy numeryczne etykiety (0-5) na polskie nazwy emocji, zliczamy wystąpienia i tworzymy wykres rozkładu.\n",
    "**Dlaczego mapowanie:** Liczby są nieczytelne dla człowieka, nazwy emocji ułatwiają interpretację wyników."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c48f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "emotion_labels = {\n",
    "    0: 'Smutek',\n",
    "    1: 'Radość',\n",
    "    2: 'Miłość',\n",
    "    3: 'Złość',\n",
    "    4: 'Strach',\n",
    "    5: 'Zaskoczenie'\n",
    "}\n",
    "\n",
    "train_emotions = [emotion_labels[label] for label in emotions['train']['label']]\n",
    "emotion_counts_text = Counter(train_emotions)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#FFA07A', '#98D8C8', '#F7DC6F', '#85C1E2']\n",
    "plt.bar(emotion_counts_text.keys(), emotion_counts_text.values(), color=colors, edgecolor='black', linewidth=1.5)\n",
    "plt.xlabel('Emocja', fontsize=13, fontweight='bold')\n",
    "plt.ylabel('Liczba przykładów', fontsize=13, fontweight='bold')\n",
    "plt.title('Rozkład emocji w zbiorze tekstowym Emotion', fontsize=15, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"STATYSTYKI EMOTION DATASET\")\n",
    "print(\"=\"*60)\n",
    "total = len(emotions['train'])\n",
    "for emotion, count in sorted(emotion_counts_text.items()):\n",
    "    percentage = (count / total) * 100\n",
    "    print(f\"{emotion:<15} {count:>6} ({percentage:>5.1f}%)\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'ŁĄCZNIE':<15} {total:>6} (100.0%)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70a7552",
   "metadata": {},
   "source": [
    "## 9. Porównanie emocji między zbiorami\n",
    "\n",
    "Mapujemy emocje z obu zbiorów na 5 wspólnych kategorii i porównujemy je side-by-side.\n",
    "**Kluczowe:** \"Radość\" i \"Miłość\" z tekstu łączymy w \"Szczęście\", ponieważ obie są pozytywne i odpowiadają kategorii \"Happy\" z AffectNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69291ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_mapping = {\n",
    "    'AffectNet': {\n",
    "        'Szczęście': emotion_counts.get('Szczęście', 0),\n",
    "        'Smutek': emotion_counts.get('Smutek', 0),\n",
    "        'Złość': emotion_counts.get('Złość', 0),\n",
    "        'Strach': emotion_counts.get('Strach', 0),\n",
    "        'Zaskoczenie': emotion_counts.get('Zaskoczenie', 0)\n",
    "    },\n",
    "    'Emotion': {\n",
    "        'Szczęście': emotion_counts_text.get('Radość', 0) + emotion_counts_text.get('Miłość', 0),\n",
    "        'Smutek': emotion_counts_text.get('Smutek', 0),\n",
    "        'Złość': emotion_counts_text.get('Złość', 0),\n",
    "        'Strach': emotion_counts_text.get('Strach', 0),\n",
    "        'Zaskoczenie': emotion_counts_text.get('Zaskoczenie', 0)\n",
    "    }\n",
    "}\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "colors = ['#4ECDC4', '#FF6B6B', '#98D8C8', '#F7DC6F', '#85C1E2']\n",
    "emotions_list = list(emotion_mapping['AffectNet'].keys())\n",
    "\n",
    "values_affectnet = list(emotion_mapping['AffectNet'].values())\n",
    "ax1.bar(emotions_list, values_affectnet, color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax1.set_xlabel('Emocja', fontsize=13, fontweight='bold')\n",
    "ax1.set_ylabel('Liczba przykładów', fontsize=13, fontweight='bold')\n",
    "ax1.set_title('AffectNet (obrazy)', fontsize=15, fontweight='bold')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "values_emotion = list(emotion_mapping['Emotion'].values())\n",
    "ax2.bar(emotions_list, values_emotion, color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax2.set_xlabel('Emocja', fontsize=13, fontweight='bold')\n",
    "ax2.set_ylabel('Liczba przykładów', fontsize=13, fontweight='bold')\n",
    "ax2.set_title('Emotion Dataset (tekst)', fontsize=15, fontweight='bold')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PORÓWNANIE WSPÓLNYCH EMOCJI\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Emocja':<15} {'AffectNet':<20} {'Emotion Dataset':<20}\")\n",
    "print(\"-\"*80)\n",
    "for emotion in emotions_list:\n",
    "    affectnet_val = emotion_mapping['AffectNet'][emotion]\n",
    "    emotion_val = emotion_mapping['Emotion'][emotion]\n",
    "    print(f\"{emotion:<15} {affectnet_val:>10} obrazów    {emotion_val:>10} tekstów\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n💡 Uwaga: Emotion 'Radość' i 'Miłość' zostały zmapowane na 'Szczęście'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f2e99e",
   "metadata": {},
   "source": [
    "## Podsumowanie\n",
    "\n",
    "✅ **AffectNet** - 30,518 obrazów z 8 kategoriami emocji  \n",
    "✅ **Emotion Dataset** - 16,000 tekstów z 6 kategoriami emocji  \n",
    "✅ **Wspólne emocje** - 5 kategorii: Szczęście, Smutek, Złość, Strach, Zaskoczenie\n",
    "\n",
    "**Mapowanie:**\n",
    "- Love (Miłość) → Szczęście (pozytywna emocja)\n",
    "- Joy (Radość) → Szczęście\n",
    "- Neutral → tylko w AffectNet (brak w tekście)\n",
    "\n",
    "Oba zbiory są gotowe do trenowania modeli wykrywania emocji! 🚀"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
