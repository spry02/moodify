{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ae17adb",
   "metadata": {},
   "source": [
    "# Analiza zbiorów danych z emocjami\n",
    "\n",
    "Ten notatnik pobiera i analizuje dwa zbiory danych:\n",
    "- **AffectNet** - zbiór obrazów z emocjami\n",
    "- **Emotion** - zbiór tekstowy z emocjami\n",
    "\n",
    "Celem jest porównanie i analiza emocji w obu zbiorach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fbbd5e",
   "metadata": {},
   "source": [
    "## 1. Instalacja bibliotek\n",
    "\n",
    "Instalujemy wymagane biblioteki do pobierania i analizy danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9ff81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kagglehub datasets matplotlib pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbdef1d",
   "metadata": {},
   "source": [
    "## 2. Pobranie zbioru AffectNet\n",
    "\n",
    "Pobieramy zbiór danych AffectNet z Kaggle zawierający obrazy twarzy z różnymi emocjami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b50a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Pobranie najnowszej wersji zbioru AffectNet\n",
    "path = kagglehub.dataset_download(\"mstjebashazida/affectnet\")\n",
    "\n",
    "print(\"Ścieżka do plików zbioru AffectNet:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74811201",
   "metadata": {},
   "source": [
    "## 3. Pobranie zbioru Emotion (tekstowy)\n",
    "\n",
    "Pobieramy zbiór danych tekstowych z emocjami z Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2c56c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Pobranie zbioru danych tekstowych z emocjami\n",
    "emotions = load_dataset(\"dair-ai/emotion\")\n",
    "\n",
    "print(\"Zbiór Emotion został pobrany pomyślnie!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ae1e73",
   "metadata": {},
   "source": [
    "## 4. Wczytanie i eksploracja AffectNet\n",
    "\n",
    "Sprawdzamy strukturę katalogu i podstawowe informacje o zbiorze AffectNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2503b849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Wyświetlenie struktury katalogów\n",
    "print(\"Zawartość katalogu AffectNet:\")\n",
    "for root, dirs, files in os.walk(path):\n",
    "    level = root.replace(path, '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f'{indent}{os.path.basename(root)}/')\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for file in files[:5]:  # Pokazujemy tylko pierwsze 5 plików\n",
    "        print(f'{subindent}{file}')\n",
    "    if len(files) > 5:\n",
    "        print(f'{subindent}... i {len(files) - 5} więcej plików')\n",
    "    if level > 2:  # Ograniczamy głębokość\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35cf9bf",
   "metadata": {},
   "source": [
    "## 5. Wyświetlenie przykładowych zdjęć z AffectNet\n",
    "\n",
    "Wyświetlamy przykładowe zdjęcia ze zbioru AffectNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f259265",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "# Znajdź obrazy w katalogu\n",
    "image_files = []\n",
    "for ext in ['*.jpg', '*.jpeg', '*.png']:\n",
    "    image_files.extend(glob.glob(os.path.join(path, '**', ext), recursive=True))\n",
    "\n",
    "# Wyświetl pierwsze 6 obrazów\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(min(6, len(image_files))):\n",
    "    img = Image.open(image_files[i])\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(f'Obraz {i+1}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nZnaleziono {len(image_files)} obrazów w zbiorze AffectNet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb30dc37",
   "metadata": {},
   "source": [
    "## 6. Analiza rozkładu emocji w AffectNet\n",
    "\n",
    "Analizujemy rozkład kategorii emocji w zbiorze AffectNet na podstawie struktury katalogów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb8e353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Mapowanie kategorii emocji AffectNet\n",
    "affectnet_emotions = {\n",
    "    '0': 'Neutralny',\n",
    "    '1': 'Szczęście',\n",
    "    '2': 'Smutek',\n",
    "    '3': 'Zaskoczenie',\n",
    "    '4': 'Strach',\n",
    "    '5': 'Wstręt',\n",
    "    '6': 'Złość',\n",
    "    '7': 'Pogarda'\n",
    "}\n",
    "\n",
    "# Zliczanie obrazów według kategorii\n",
    "emotion_counts = Counter()\n",
    "\n",
    "for img_path in image_files:\n",
    "    # Próba wykrycia kategorii z nazwy pliku lub ścieżki\n",
    "    parts = Path(img_path).parts\n",
    "    for part in parts:\n",
    "        if part in affectnet_emotions:\n",
    "            emotion_counts[affectnet_emotions[part]] += 1\n",
    "            break\n",
    "\n",
    "# Jeśli nie znaleziono kategorii w ścieżce, dodaj ogólną kategorię\n",
    "if not emotion_counts:\n",
    "    emotion_counts['Wszystkie emocje'] = len(image_files)\n",
    "\n",
    "# Wykres słupkowy\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(emotion_counts.keys(), emotion_counts.values(), color='skyblue')\n",
    "plt.xlabel('Emocja', fontsize=12)\n",
    "plt.ylabel('Liczba obrazów', fontsize=12)\n",
    "plt.title('Rozkład emocji w zbiorze AffectNet', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nStatystyki zbioru AffectNet:\")\n",
    "for emotion, count in emotion_counts.items():\n",
    "    print(f\"{emotion}: {count} obrazów\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760745ab",
   "metadata": {},
   "source": [
    "## 7. Wczytanie i eksploracja zbioru Emotion\n",
    "\n",
    "Wyświetlamy strukturę i podstawowe informacje o zbiorze tekstowym Emotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9f3d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyświetlenie struktury zbioru\n",
    "print(\"Struktura zbioru Emotion:\")\n",
    "print(emotions)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Wyświetlenie podziałów\n",
    "print(\"Podział zbioru:\")\n",
    "for split in emotions.keys():\n",
    "    print(f\"  {split}: {len(emotions[split])} przykładów\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Wyświetlenie przykładowych danych\n",
    "print(\"Przykładowe dane ze zbioru treningowego:\")\n",
    "for i in range(3):\n",
    "    print(f\"\\nPrzykład {i+1}:\")\n",
    "    print(f\"  Tekst: {emotions['train'][i]['text']}\")\n",
    "    print(f\"  Emocja: {emotions['train'][i]['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a7287c",
   "metadata": {},
   "source": [
    "## 8. Analiza rozkładu emocji w zbiorze tekstowym\n",
    "\n",
    "Tworzymy wykres pokazujący rozkład emocji w zbiorze tekstowym Emotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c48f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Mapowanie etykiet na nazwy emocji\n",
    "emotion_labels = {\n",
    "    0: 'Smutek',\n",
    "    1: 'Radość',\n",
    "    2: 'Miłość',\n",
    "    3: 'Złość',\n",
    "    4: 'Strach',\n",
    "    5: 'Zaskoczenie'\n",
    "}\n",
    "\n",
    "# Zliczanie emocji w zbiorze treningowym\n",
    "train_emotions = [emotion_labels[label] for label in emotions['train']['label']]\n",
    "emotion_counts_text = Counter(train_emotions)\n",
    "\n",
    "# Wykres słupkowy\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(emotion_counts_text.keys(), emotion_counts_text.values(), color='lightcoral')\n",
    "plt.xlabel('Emocja', fontsize=12)\n",
    "plt.ylabel('Liczba przykładów', fontsize=12)\n",
    "plt.title('Rozkład emocji w zbiorze tekstowym Emotion (zbiór treningowy)', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nStatystyki zbioru tekstowego Emotion:\")\n",
    "for emotion, count in emotion_counts_text.items():\n",
    "    print(f\"{emotion}: {count} przykładów\")\n",
    "print(f\"\\nŁącznie: {len(emotions['train'])} przykładów treningowych\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda58166",
   "metadata": {},
   "source": [
    "## 9. Porównanie kategorii emocji między zbiorami\n",
    "\n",
    "Porównujemy kategorie emocji występujące w obu zbiorach i identyfikujemy wspólne emocje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c8d3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emocje z AffectNet\n",
    "affectnet_emotion_set = set(affectnet_emotions.values())\n",
    "\n",
    "# Emocje z zbioru tekstowego\n",
    "text_emotion_set = set(emotion_labels.values())\n",
    "\n",
    "print(\"PORÓWNANIE EMOCJI W OBU ZBIORACH\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nEmocje w zbiorze AffectNet:\")\n",
    "for emotion in sorted(affectnet_emotion_set):\n",
    "    print(f\"  - {emotion}\")\n",
    "\n",
    "print(\"\\nEmocje w zbiorze tekstowym Emotion:\")\n",
    "for emotion in sorted(text_emotion_set):\n",
    "    print(f\"  - {emotion}\")\n",
    "\n",
    "# Wspólne emocje\n",
    "common_emotions = affectnet_emotion_set.intersection(text_emotion_set)\n",
    "print(f\"\\nWspólne emocje ({len(common_emotions)}):\")\n",
    "for emotion in sorted(common_emotions):\n",
    "    print(f\"  ✓ {emotion}\")\n",
    "\n",
    "# Unikalne dla każdego zbioru\n",
    "affectnet_unique = affectnet_emotion_set - text_emotion_set\n",
    "text_unique = text_emotion_set - affectnet_emotion_set\n",
    "\n",
    "print(f\"\\nEmocje tylko w AffectNet ({len(affectnet_unique)}):\")\n",
    "for emotion in sorted(affectnet_unique):\n",
    "    print(f\"  - {emotion}\")\n",
    "\n",
    "print(f\"\\nEmocje tylko w zbiorze tekstowym ({len(text_unique)}):\")\n",
    "for emotion in sorted(text_unique):\n",
    "    print(f\"  - {emotion}\")\n",
    "\n",
    "# Wizualizacja porównania\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Wykres dla AffectNet\n",
    "ax1.bar(range(len(affectnet_emotion_set)), [1]*len(affectnet_emotion_set), color='skyblue')\n",
    "ax1.set_xticks(range(len(affectnet_emotion_set)))\n",
    "ax1.set_xticklabels(sorted(affectnet_emotion_set), rotation=45, ha='right')\n",
    "ax1.set_ylabel('Obecność')\n",
    "ax1.set_title('Kategorie emocji w AffectNet', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylim(0, 1.5)\n",
    "\n",
    "# Wykres dla zbioru tekstowego\n",
    "ax2.bar(range(len(text_emotion_set)), [1]*len(text_emotion_set), color='lightcoral')\n",
    "ax2.set_xticks(range(len(text_emotion_set)))\n",
    "ax2.set_xticklabels(sorted(text_emotion_set), rotation=45, ha='right')\n",
    "ax2.set_ylabel('Obecność')\n",
    "ax2.set_title('Kategorie emocji w zbiorze tekstowym', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylim(0, 1.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70a7552",
   "metadata": {},
   "source": [
    "## Podsumowanie\n",
    "\n",
    "Przeanalizowaliśmy dwa zbiory danych z emocjami:\n",
    "- **AffectNet** - zbiór obrazów zawierający 8 kategorii emocji\n",
    "- **Emotion** - zbiór tekstowy zawierający 6 kategorii emocji\n",
    "\n",
    "Wspólne emocje w obu zbiorach to podstawowe uczucia, które mogą być wykorzystane do budowy multimodalnego systemu rozpoznawania emocji."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
